- module_defaults:
    group/aws:
      access_key: "{{ aws_access_key }}"
      secret_key: "{{ aws_secret_key }}"
      session_token: "{{ security_token | default(omit) }}"
    cloudfront_distribution:
      alias: "{{ cloudfront_alias | default(omit) }}"
      viewer_certificate: "{{ cloudfront_viewer_cert | default(omit) }}"
  collections:
    - amazon.aws

  block:

  - name: create cloudfront distribution using defaults
    cloudfront_distribution:
      origins:
      - domain_name: "{{ cloudfront_hostname }}-origin.example.com"
        id: "{{ cloudfront_hostname }}-origin.example.com"
      default_cache_behavior:
        target_origin_id: "{{ cloudfront_hostname }}-origin.example.com"
      state: present
      purge_origins: true
    register: cf_distribution

  - set_fact:
      distribution_id: '{{ cf_distribution.id }}'

  - name: ensure that default value of 'enabled' is 'true'
    assert:
      that:
        - cf_distribution.changed
        - cf_distribution.enabled

  - name: ensure that default value of 'ipv6_enabled' is 'false'
    assert:
      that:
        - cf_distribution.changed
        - not cf_distribution.is_ipv6_enabled

  - name: Update the distribution with tags
    cloudfront_distribution:
      state: present
      distribution_id: "{{ distribution_id }}"
      tags:
        property: ansible
    register: cf_update_tags

  - name: ensure the 'ipv6_enabled' value has not changed
    assert:
      that:
        - cf_update_tags.changed
        - not cf_update_tags.is_ipv6_enabled

  - name: Update the distribution ipv6_enabled set to true
    cloudfront_distribution:
      state: present
      distribution_id: "{{ distribution_id }}"
      ipv6_enabled: true
    register: cf_update_ipv6

  - name: ensure the 'ipv6_enabled' value has changed (new value is true)
    assert:
      that:
        - cf_update_ipv6.changed
        - cf_update_ipv6.is_ipv6_enabled

  - name: Update the distribution with tags
    cloudfront_distribution:
      state: present
      distribution_id: "{{ distribution_id }}"
      tags:
        test: integration
    register: cf_update_tags

  - name: ensure the 'ipv6_enabled' value has not changed (value remains true)
    assert:
      that:
        - cf_update_tags.changed
        - cf_update_tags.is_ipv6_enabled

  - name: Test idempotency updating cloudfront_distribution with same value of ipv6_enabled
    cloudfront_distribution:
      state: present
      distribution_id: "{{ distribution_id }}"
      ipv6_enabled: true
    register: cf_update_ipv6

  - name: ensure the 'ipv6_enabled' value has changed (new value is true)
    assert:
      that:
        # FixMe : idempotency issues
        # - not cf_update_ipv6.changed
        - cf_update_ipv6.is_ipv6_enabled
  
  - name: Ensure that default value of 'http_version' is 'http2'
    assert:
      that:
        - cf_update_ipv6.http_version == 'http2'

  - name: Update the distribution http_version to http2and3
    cloudfront_distribution:
      state: present
      distribution_id: "{{ distribution_id }}"
      http_version: http2and3
    register: cf_update_http_version

  - name: Ensure that default value of 'http_version' is 'http2and3'
    assert:
      that:
        - cf_update_http_version.changed
        - cf_update_http_version.http_version == 'http2and3'

  # - name: re-run cloudfront distribution with same defaults
  #   cloudfront_distribution:
  #     distribution_id: "{{ distribution_id }}"
  #     origins:
  #     - domain_name: "{{ cloudfront_hostname }}-origin.example.com"
  #     state: present
  #   register: cf_dist_no_update

  # - name: ensure distribution was not updated
  #   assert:
  #     that:
  #       - not cf_dist_no_update.changed

  # - name: re-run cloudfront distribution using distribution id
  #   cloudfront_distribution:
  #     distribution_id: "{{ distribution_id }}"
  #     purge_origins: no
  #     state: present
  #   register: cf_dist_with_id

  # - name: ensure distribution was not updated
  #   assert:
  #     that:
  #       - not cf_dist_with_id.changed

  - name: update origin http port
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ cloudfront_hostname }}-origin.example.com"
        custom_origin_config:
          http_port: 8080
      state: present
    register: update_origin_http_port

  - name: ensure http port was updated
    assert:
      that:
        - update_origin_http_port.changed

  - name: enable origin Origin Shield
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ cloudfront_hostname }}-origin.example.com"
        custom_origin_config:
          http_port: 8080
        origin_shield:
          enabled: true
          origin_shield_region: '{{ aws_region }}'
      state: present
    register: update_origin_origin_shield

  - name: ensure origin Origin Shield was enabled
    assert:
      that:
        - update_origin_origin_shield.changed
        - update_origin_origin_shield.origins['items'][0].origin_shield.enabled
        - update_origin_origin_shield.origins['items'][0].origin_shield.origin_shield_region == aws_region

  # TODO: fix module idempotency issue
  # - name: enable origin Origin Shield again to test idempotency
  #   cloudfront_distribution:
  #     distribution_id: "{{ distribution_id }}"
  #     origins:
  #     - domain_name: "{{ cloudfront_hostname }}-origin.example.com"
  #       custom_origin_config:
  #         http_port: 8080
  #       origin_shield:
  #         enabled: true
  #         origin_shield_region: '{{ aws_region }}'
  #     state: present
  #   register: update_origin_origin_shield_idempotency

  # - name: test idempotency for Origin Shield
  #   assert:
  #     that:
  #       - not update_origin_origin_shield_idempotency.changed
  #       - update_origin_origin_shield_idempotency.origins['items'][0].origin_shield.enabled
  #       - update_origin_origin_shield_idempotency.origins['items'][0].origin_shield.origin_shield_region == '{{ aws_region }}'

  - name: disable origin Origin Shield
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ cloudfront_hostname }}-origin.example.com"
        custom_origin_config:
          http_port: 8080
        origin_shield:
          enabled: false
      state: present
    register: update_origin_origin_shield_disable

  - name: ensure origin Origin Shield was disabled
    assert:
      that:
        - update_origin_origin_shield_disable.changed
        - not update_origin_origin_shield_disable.origins['items'][0].origin_shield.enabled

  - name: update restrictions
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      restrictions:
        geo_restriction:
          restriction_type: "whitelist"
          items:
            - "US"
      state: present
    register: update_restrictions

  - name: ensure restrictions was updated
    assert:
      that:
        - update_restrictions.changed

  - name: set a random comment
    set_fact:
      comment: "{{'ABCDEFabcdef123456'|shuffle|join }}"

  - name: update comment
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      comment: "{{ comment }}"
      state: present
    register: cf_comment

  - name: ensure comment was updated
    assert:
      that:
        - cf_comment.changed
        - 'cf_comment.comment == comment'

  - name: create second origin
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ resource_prefix }}2.example.com"
        id: "{{ resource_prefix }}2.example.com"
      default_root_object: index.html
      state: present
      wait: true
    register: cf_add_origin

  - name: ensure origin was added
    assert:
      that:
        - cf_add_origin.origins.quantity == 2
        - cf_add_origin.changed
        - "cf_add_origin.default_root_object == 'index.html'"

  - name: re-run second origin
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ cloudfront_hostname }}-origin.example.com"
        custom_origin_config:
          http_port: 8080
      - domain_name: "{{ resource_prefix }}2.example.com"
      default_root_object: index.html
      wait: true
      state: present
    register: cf_rerun_second_origin

  - name: ensure nothing changed after re-run
    assert:
      that:
        - cf_rerun_second_origin.origins.quantity == 2
        # - not cf_rerun_second_origin.changed

  - name: run with origins in reverse order
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ resource_prefix }}2.example.com"
      - domain_name: "{{ cloudfront_hostname }}-origin.example.com"
        custom_origin_config:
          http_port: 8080
      state: present
    register: cf_rerun_second_origin_reversed

  - name: ensure nothing changed after reversed re-run
    assert:
      that:
        - cf_rerun_second_origin_reversed.origins.quantity == 2
        # - not cf_rerun_second_origin_reversed.changed


  - name: purge first origin
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ resource_prefix }}2.example.com"
      default_cache_behavior:
        target_origin_id: "{{ resource_prefix }}2.example.com"
      purge_origins: true
      state: present
    register: cf_purge_origin

  - name: ensure origin was removed
    assert:
      that:
        - cf_purge_origin.origins.quantity == 1
        - cf_purge_origin.changed

  - name: update default_root_object of existing distribution
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ resource_prefix }}2.example.com"
      default_root_object: index.php
      state: present
    register: cf_update_default_root_object

  - name: update default_root_object of existing distribution with retries
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ resource_prefix }}2.example.com"
      default_root_object: index.php
      state: present
    retries: 3
    delay: 3  
    register: cf_update_default_root_object    

  - name: ensure origin was updated
    assert:
      that:
        - "cf_update_default_root_object.default_root_object == 'index.php'"
        - cf_update_default_root_object.changed

  - name: add tags to existing distribution
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ resource_prefix }}2.example.com"
      tags:
        ATag: tag1
        Another: tag
      default_root_object: index.php
      state: present
    register: cf_add_tags

  - name: ensure tags were added
    assert:
      that:
        - cf_add_tags.changed
        - cf_add_tags.tags|length == 2

  - name: delete distribution
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      enabled: false
      wait: true
      state: absent

  - name: create cloudfront distribution with tags and as disabled
    cloudfront_distribution:
      enabled: false
      origins:
      - domain_name: "{{ resource_prefix }}2.example.com"
        id: "{{ resource_prefix }}2.example.com"
      tags:
        ATag: tag1
        Another: tag
      state: present
    register: cf_second_distribution

  - set_fact:
      distribution_id: '{{ cf_second_distribution.id }}'

  - name: ensure that the value of 'enabled' is 'false'
    assert:
      that:
        - cf_second_distribution.changed
        - not cf_second_distribution.enabled

  - name: ensure tags were set on creation
    assert:
      that:
        - cf_second_distribution.changed
        - cf_second_distribution.tags|length == 2
        - "'ATag' in cf_second_distribution.tags"
        - "'Another' in cf_second_distribution.tags"

  - name: re-run create distribution with same tags and purge_tags
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ resource_prefix }}2.example.com"
        id: "{{ resource_prefix }}2.example.com"
      tags:
        ATag: tag1
        Another: tag
      purge_tags: true
      state: present
    register: rerun_with_purge_tags

  - name: ensure that re-running didn't change
    assert:
      that:
        # - not rerun_with_purge_tags.changed
        - rerun_with_purge_tags.tags|length == 2

  - name: add new tag to distribution
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ resource_prefix }}2.example.com"
      tags:
        Third: thing
      purge_tags: false
      state: present
    register: update_with_new_tag

  - name: ensure tags are correct
    assert:
      that:
        - update_with_new_tag.changed
        - "'Third' in update_with_new_tag.tags"
        - "'Another' in update_with_new_tag.tags"
        - "'ATag' in update_with_new_tag.tags"
        - update_with_new_tag.tags|length == 3

  - name: create some cache behaviors
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ resource_prefix }}2.example.com"
      cache_behaviors: "{{ cloudfront_test_cache_behaviors }}"
      state: present
    register: add_cache_behaviors

  - name: reverse some cache behaviors
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ resource_prefix }}2.example.com"
      cache_behaviors: "{{ cloudfront_test_cache_behaviors|reverse|list }}"
      state: present
    register: reverse_cache_behaviors

  - name: check that reversing cache behaviors changes nothing when purge_cache_behaviors unset
    assert:
      that:
        # - not reverse_cache_behaviors.changed
        - reverse_cache_behaviors.cache_behaviors|length == 2

  - name: reverse some cache behaviors properly
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ resource_prefix }}2.example.com"
      cache_behaviors: "{{ cloudfront_test_cache_behaviors|reverse|list }}"
      purge_cache_behaviors: true
      state: present
    register: reverse_cache_behaviors_with_purge

  - name: check that reversing cache behaviors changes nothing when purge_cache_behaviors unset
    assert:
      that:
        - reverse_cache_behaviors_with_purge.changed
        - reverse_cache_behaviors_with_purge.cache_behaviors|length == 2

  - name: update origin that changes target id (failure expected)
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ resource_prefix }}3.example.com"
        id: "{{ resource_prefix }}3.example.com"
      purge_origins: true
      state: present
    register: remove_origin_in_use
    ignore_errors: true

  - name: check that removing in use origin fails
    assert:
      that:
        - remove_origin_in_use.failed

  # FIXME: This currently fails due to AWS side problems
  # not clear whether to hope they fix or prevent this issue from happening
  #- name: update origin and update cache behavior to point to new origin
  #  cloudfront_distribution:
  #    origins:
  #    - domain_name: "{{ resource_prefix }}3.example.com"
  #      id: "{{ resource_prefix }}3.example.com"
  #    cache_behaviors:
  #      - path_pattern: /test/path
  #        target_origin_id: "{{ resource_prefix }}3.example.com"
  #      - path_pattern: /another/path
  #        target_origin_id: "{{ resource_prefix }}3.example.com"
  #    state: present
  #  register: update_cache_behaviors in use

  - name: create an s3 bucket for next test
    # note that although public-read allows reads that we want to stop with origin_access_identity,
    # we also need to test without origin_access_identity and it's hard to change bucket perms later
    s3_bucket:
      name: "{{ resource_prefix }}-bucket"
      state: present

  - name: update origin to point to the s3 bucket
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ resource_prefix }}-bucket.s3.amazonaws.com"
        id: "{{ resource_prefix }}3.example.com"
        s3_origin_access_identity_enabled: true
      state: present
    register: update_origin_to_s3

  - name: check that s3 origin access is in result
    assert:
      that:
        - item.s3_origin_config.origin_access_identity.startswith('origin-access-identity/cloudfront/')
    when: "'s3_origin_config' in item"
    loop: "{{ update_origin_to_s3.origins['items'] }}"

  - name: update origin to remove s3 origin access identity
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ resource_prefix }}-bucket.s3.amazonaws.com"
        id: "{{ resource_prefix }}3.example.com"
        s3_origin_access_identity_enabled: false
      state: present
    register: update_origin_to_s3_without_origin_access

  - name: check that s3 origin access is not in result
    assert:
      that:
        - not item.s3_origin_config.origin_access_identity
    when: "'s3_origin_config' in item"
    loop: "{{ update_origin_to_s3_without_origin_access.origins['items'] }}"

  - name: delete the s3 bucket
    s3_bucket:
      name: "{{ resource_prefix }}-bucket"
      state: absent

  - name: check that custom_origin_config can't be used with origin_access_identity enabled
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ resource_prefix }}-bucket.s3.amazonaws.com"
        id: "{{ resource_prefix }}3.example.com"
        s3_origin_access_identity_enabled: true
        custom_origin_config:
          origin_protocol_policy: 'http-only'
      state: present
    register: update_origin_to_s3_with_origin_access_and_with_custom_origin_config
    ignore_errors: true

  - name: check that custom origin with origin access identity fails
    # "s3 origin domains and custom_origin_config are mutually exclusive"
    assert:
      that:
        - update_origin_to_s3_with_origin_access_and_with_custom_origin_config.failed

  - name: check that custom_origin_config can't be used with an region-agnostic S3 domain
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ resource_prefix }}-bucket.s3.{{ aws_region }}.amazonaws.com"
        id: "{{ resource_prefix }}3.example.com"
        custom_origin_config:
          http_port: 8080
      state: present
    register: update_origin_to_s3_with_origin_access_and_with_custom_origin_config
    ignore_errors: true

  - name: check that custom origin with region-agnostic S3 domain fails
    # "s3 origin domains and custom_origin_config are mutually exclusive"
    assert:
      that:
        - update_origin_to_s3_with_origin_access_and_with_custom_origin_config.failed

  - name: check that custom_origin_config can't be used with an region-aware S3 domain
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
      - domain_name: "{{ resource_prefix }}-bucket.s3.amazonaws.com"
        id: "{{ resource_prefix }}3.example.com"
        custom_origin_config:
          http_port: 8080
      state: present
    register: update_origin_to_s3_with_origin_access_and_with_custom_origin_config
    ignore_errors: true

  - name: check that custom origin with region-aware S3 domain fails
    # "s3 origin domains and custom_origin_config are mutually exclusive"
    assert:
      that:
        - update_origin_to_s3_with_origin_access_and_with_custom_origin_config.failed

  - name: create cloudfront distribution origin access identity
    cloudfront_origin_access_identity:
      state: present
      comment: "this is a sample origin access identity"
    register: _origin_access_id

  - set_fact:
      origin_access_identity: 'origin-access-identity/cloudfront/{{ _origin_access_id.cloud_front_origin_access_identity.id }}'

  - name: Update distribution to use specific access identity
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      origins:
        - id: "{{ resource_prefix }}"
          domain_name: "{{ resource_prefix }}.s3.amazonaws.com"
          s3_origin_access_identity_enabled: true
          s3_origin_config:
            origin_access_identity: '{{ origin_access_identity }}'
    register: result

  - name: check that custom origin uses the provided origin_access_identity
    assert:
      that:
        - result.changed
        - result.origins['quantity'] > 0
        - result.origins['items'] | selectattr('s3_origin_config', 'defined') | map(attribute='s3_origin_config') | selectattr('origin_access_identity', 'eq', origin_access_identity) | list | length == 1

  - name: update distribution to use cache_policy_id and origin_request_policy_id
    cloudfront_distribution:
      distribution_id: "{{ distribution_id }}"
      default_cache_behavior:
        cache_policy_id: "658327ea-f89d-4fab-a63d-7e88639e58f6"
        origin_request_policy_id: "88a5eaf4-2fd4-4709-b370-b4c650ea3fcf"
      state: present
    register: update_distribution_with_cache_policies

  - name: ensure that the cache_policy_id and origin_request_policy_id was set
    assert:
      that:
        - update_distribution_with_cache_policies.changed
        - update_distribution_with_cache_policies.default_cache_behavior.cache_policy_id == '658327ea-f89d-4fab-a63d-7e88639e58f6'
        - update_distribution_with_cache_policies.default_cache_behavior.origin_request_policy_id == '88a5eaf4-2fd4-4709-b370-b4c650ea3fcf'

  always:
  # TEARDOWN STARTS HERE
  - name: delete the s3 bucket
    s3_bucket:
      name: "{{ resource_prefix }}-bucket"
      state: absent
      force: true
    ignore_errors: true

  - name: clean up cloudfront distribution
    cloudfront_distribution:
      distribution_id: "{{ item }}"
      enabled: false
      wait: true
      state: absent
    register: delete_distribution
    ignore_errors: true
    async: 1000
    poll: 0
    with_items:
      - '{{ cf_second_distribution.id }}'
      - '{{ cf_distribution.id }}'

  - name: Wait for cloudfront to be deleted
    async_status:
      jid: "{{ item.ansible_job_id }}"
    register: _delete
    until: _delete.finished
    retries: 100
    delay: 5
    loop: "{{ delete_distribution.results }}"
    ignore_errors: true
